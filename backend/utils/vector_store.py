import json
import os
import math
from .openai_client import create_embedding

def load_vectorstore():
    """Load vectorstore tá»« shared folder"""
    try:
        vectorstore_path = "../vectorstore/embedded_docs.json"
        print(f"ğŸ“ Äang táº£i vectorstore tá»«: {vectorstore_path}")

        if not os.path.exists(vectorstore_path):
            print(f"âŒ KhÃ´ng tÃ¬m tháº¥y file: {vectorstore_path}")
            return []

        with open(vectorstore_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            print(f"âœ… ÄÃ£ táº£i {len(data)} documents tá»« vectorstore")
            return data
    except Exception as e:
        print(f"âŒ Lá»—i táº£i vectorstore: {e}")
        return []

def embed_text(text: str):
    """Embed text using OpenAI - sá»­ dá»¥ng GPT-4o-mini thay vÃ¬ embedding model"""
    try:
        print(f"ğŸ”¤ Äang embed text: {text[:50]}...")

        # Sá»­ dá»¥ng GPT-4o-mini Ä‘á»ƒ táº¡o embedding Ä‘Æ¡n giáº£n
        # Trong thá»±c táº¿, báº¡n nÃªn dÃ¹ng embedding model, nhÆ°ng táº¡m thá»i dÃ¹ng cÃ¡ch nÃ y
        prompt = f"""
        Táº¡o má»™t vector embedding Ä‘Æ¡n giáº£n cho vÄƒn báº£n sau báº±ng cÃ¡ch tráº£ vá» má»™t máº£ng sá»‘:
        "{text}"

        Chá»‰ tráº£ vá» máº£ng JSON, khÃ´ng cÃ³ text nÃ o khÃ¡c.
        """

        from .openai_client import chat_completion
        response = chat_completion([
            {"role": "user", "content": prompt}
        ])

        if response and 'choices' in response and len(response['choices']) > 0:
            content = response['choices'][0]['message']['content'].strip()

            # Loáº¡i bá» markdown code blocks náº¿u cÃ³
            if content.startswith("```json"):
                content = content[7:-3].strip()
            elif content.startswith("```"):
                content = content[3:-3].strip()

            embedding = json.loads(content)
            print("âœ… Embed text thÃ nh cÃ´ng!")
            return embedding
        else:
            print("âŒ KhÃ´ng nháº­n Ä‘Æ°á»£c embedding tá»« GPT")
            return get_simple_embedding(text)

    except Exception as e:
        print(f"âŒ Lá»—i embed text vá»›i GPT: {e}")
        return get_simple_embedding(text)

def get_simple_embedding(text: str):
    """Táº¡o embedding Ä‘Æ¡n giáº£n dá»±a trÃªn tá»« khÃ³a (fallback)"""
    print("ğŸ”„ Sá»­ dá»¥ng simple embedding fallback...")

    # Tá»« khÃ³a quan trá»ng cho backend development
    backend_keywords = ["python", "flask", "django", "api", "rest", "database", "sql", "server", "backend", "web"]

    # Táº¡o embedding Ä‘Æ¡n giáº£n dá»±a trÃªn sá»± xuáº¥t hiá»‡n cá»§a tá»« khÃ³a
    embedding = []
    text_lower = text.lower()

    for keyword in backend_keywords:
        if keyword in text_lower:
            embedding.append(1.0)
        else:
            embedding.append(0.0)

    # ThÃªm padding náº¿u cáº§n
    while len(embedding) < 10:
        embedding.append(0.0)

    print(f"âœ… Táº¡o simple embedding vá»›i {len(embedding)} dimensions")
    return embedding

def dot_product(a, b):
    """TÃ­nh dot product thá»§ cÃ´ng"""
    if len(a) != len(b):
        # Padding Ä‘á»ƒ cÃ¹ng chiá»u dÃ i
        max_len = max(len(a), len(b))
        a = a + [0] * (max_len - len(a))
        b = b + [0] * (max_len - len(b))
    return sum(x * y for x, y in zip(a, b))

def magnitude(vector):
    """TÃ­nh magnitude thá»§ cÃ´ng"""
    return math.sqrt(sum(x * x for x in vector))

def cosine_similarity(a, b):
    """Cosine similarity khÃ´ng dÃ¹ng numpy"""
    if not a or not b:
        return 0
    dot_prod = dot_product(a, b)
    mag_a = magnitude(a)
    mag_b = magnitude(b)
    return dot_prod / (mag_a * mag_b) if mag_a != 0 and mag_b != 0 else 0

def search_courses(query: str, top_k: int = 5):
    """TÃ¬m khÃ³a há»c phÃ¹ há»£p dá»±a trÃªn query"""
    print(f"ğŸ” Äang tÃ¬m kiáº¿m khÃ³a há»c vá»›i query: {query[:100]}...")

    vectorstore = load_vectorstore()
    if not vectorstore:
        print("âŒ Vectorstore trá»‘ng!")
        return []

    query_embedding = embed_text(query)
    if not query_embedding:
        print("âŒ KhÃ´ng thá»ƒ táº¡o query embedding!")
        return []

    similarities = []

    for doc in vectorstore:
        # Sá»­ dá»¥ng similarity Ä‘Æ¡n giáº£n dá»±a trÃªn tá»« khÃ³a
        doc_text = doc.get("text", "").lower()
        query_lower = query.lower()

        # TÃ­nh similarity Ä‘Æ¡n giáº£n
        sim = simple_text_similarity(query_lower, doc_text)
        similarities.append((sim, doc))

    # Sáº¯p xáº¿p theo Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giáº£m dáº§n
    similarities.sort(key=lambda x: x[0], reverse=True)

    # Láº¥y cÃ¡c khÃ³a há»c duy nháº¥t
    unique_courses = {}
    for sim, doc in similarities:
        course_title = doc["course_title"]
        if course_title not in unique_courses:
            unique_courses[course_title] = {
                "course_title": course_title,
                "text": doc["text"],
                "similarity": float(sim)
            }
        if len(unique_courses) >= top_k:
            break

    print(f"âœ… TÃ¬m tháº¥y {len(unique_courses)} khÃ³a há»c phÃ¹ há»£p")
    return list(unique_courses.values())

def simple_text_similarity(text1: str, text2: str):
    """TÃ­nh similarity Ä‘Æ¡n giáº£n dá»±a trÃªn tá»« khÃ³a chung"""
    backend_keywords = ["python", "flask", "django", "api", "rest", "database", "sql", "server", "backend", "web", "development"]

    score = 0
    text1_lower = text1.lower()
    text2_lower = text2.lower()

    for keyword in backend_keywords:
        if keyword in text1_lower and keyword in text2_lower:
            score += 1

    # Chuáº©n hÃ³a score vá» 0-1
    max_score = len(backend_keywords)
    return score / max_score if max_score > 0 else 0
